{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size,num_steps  = 32,35\n",
    "train_iter,vocab = d2l.load_data_time_machine(batch_size,num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.nn.functional.one_hot` 是 PyTorch 中用于将标签或索引转换为独热编码（one-hot encoding）格式的函数。它通常用于处理分类任务中的标签数据。 \n",
    "- input：一个包含类别标签的张量，一般是一个整数张量。每个整数表示类别的索引。\n",
    "- num_classes：类别的总数，即独热编码向量的长度。这个参数是可选的，如果不指定，PyTorch 会自动根据输入张量中的最大值来推断类别数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 独热编码\n",
    "F.one_hot(torch.tensor([0,2]),len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2,5))\n",
    "F.one_hot(X.T,28).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  初始化RNN网络模型的模型参数\n",
    "def get_params(vocab_size,num_hiddens,device):\n",
    "    num_inputs = num_outputs = vocab_size\n",
    "\n",
    "    def normal(shape):\n",
    "        return torch.randn(size = shape,device=device)*0.01\n",
    "\n",
    "    W_xh = normal((num_inputs,num_hiddens))\n",
    "    W_hh = normal((num_hiddens,num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens,device=device)\n",
    "    W_hq = normal((num_hiddens,num_outputs))\n",
    "    b_q = torch.zeros(num_outputs,device=device)\n",
    "    params = [W_hh,W_hh,b_h,W_hq,b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad(True)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一个init_rnn_state函数在初始化时返回隐藏状态\n",
    "def init_rnn_state(batch_size,num_hiddens,device):\n",
    "    return (torch.zeros((batch_size,num_hiddens),device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下面的rnn函数定义了如何在一个时间步计算隐藏状态和输出\n",
    "def rnn(inputs,state,params):\n",
    "    W_xh,W_hh,b_h,W_hp,b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    for X in inputs:\n",
    "        H = torch.tanh((torch.mm(X,W_xh)+torch.mm(H,W_hh)+b_h))\n",
    "        Y = torch.mm(H,W_hq)+b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs,dim=0),(H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个类来包装这些函数\n",
    "class RNNModelScratch:\n",
    "    \"\"\"从零开始实现循环神经网络模型\"\"\"\n",
    "    def __init__(self,vocab_size,num_hiddens,device,get_params,init_state,forward_fn):\n",
    "        self.vocab_size,self.num_hiddens = vocab_size,num_hiddens\n",
    "        self.params = get_params(vocab_size,num_hiddens,device)\n",
    "        self.init_state,self.forward_fn = init_state,forward_fn\n",
    "    \n",
    "    def __call__(self,X,state):\n",
    "        X = F.one_hot(X.T,self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X,state,self.params)\n",
    "    \n",
    "    def begin_state(self,batch_size,device):\n",
    "        return self.init_state(batch_size,self.num_hiddens,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vacab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 检查输出是否具有正确的形状\u001b[39;00m\n\u001b[0;32m      2\u001b[0m num_hiddens \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[1;32m----> 3\u001b[0m net \u001b[38;5;241m=\u001b[39m RNNModelScratch(\u001b[38;5;28mlen\u001b[39m(\u001b[43mvacab\u001b[49m),)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vacab' is not defined"
     ]
    }
   ],
   "source": [
    "# 检查输出是否具有正确的形状\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vacab),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
